---
title: "0167-empiricalyang-9noun-hfrule-adults-fastproduction"
author: "Kathryn Schuler"
date: "last updated 2017-02-01"
output: 
  html_document:
    theme: default
    toc: TRUE
    toc_float: FALSE
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

This experiment was conducted by Kathryn Schuler (graduate student) and Elissa Newport (advisor) and was based on a theory and computational model proposed by Charles Yang (U. Penn) and the declarative-procedural memory circuit framework proposed by Michael Ullman (Georgetown University). The lab manager at the time of running was Jaclyn Horowitz and the research assistant involved in this project was Gabriella Iskin (undergraduate RA).  The data was collected at Georgetown University from November 11, 2016 to ONGOING.

- This experiment was reported in:
    - nothing, yet.
- And is planned to be reported in:
    - 2017 - Katie's job talk at Penn
    - 2017 - Katie's dissertation

# Introduction

A brief abstract here. (UPDATE ME)


# Materials and Method
## Subjects
- Adults:
    - 21 adults recruited at Georgetown University (13 female)
    - additional 2 excluded for failing to complete the study (2 male)
    - native English speakers (but multilingual permitted)
    - compensated $15.00 ($10.00 with a $5.00 bonus)

## Materials
### Equipment
  - Hardware: 
      - Macbook Air (OSX) 
      - Sennheiser HD555 open-air headphones
      - Internal microphone of Macbook Air
  - Software: Python, PsychoPy 
      - Note: Audacity used for some recordings as PsychoPy's microphone API unreliable
    
### Language
- 15 total nouns: 
    - 9 familiar: `mawg`, `tombur`, `glim`, `zup`, `spad`, `daygin`, `flairb`, `clidam`, `lapal`
    - 6 novel: `bleggin`, `daffin`, `norg`, `sep`, `flugit`, `geed` 
- 1 verb: `gentif` (means "there is" or "there are")
- 7 plural markers: 
    - 1 regular form: `ka` (applied to most frequent nouns)
    - 6 exceptions: `po`, `lee`, `bae`, `tay`, `muy`, `woo`
- Sentences constructed:
    - Singular: `V` + `N` + `null` (e.g. `gentif mawg`)
    - Plural: `V` + `N` + `MARKER` (e.g. `gentif mawg ka`)
- Conditions:
    - 5R4E Exposure: 5 most frequent types take the regular form `ka` and 4 remaining types take exceptions.
        - Language A: Noun rank in Zipfian distribution is as listed above (`mawg` is most frequent)
        - Language B: Noun rank is reversed (`lapal` is most frequent)
    - 3R6E Exposure: 3 most frequent types take the regular form `ka` and 6 remaining types take exceptions.
        - Language A: Noun rank in Zipfian distribution is as listed above (`mawg` is most frequent)
        - Language B: Noun rank is reversed (`lapal` is most frequent)

### Stimuli
- Images of "toasters" and pre-recorded words (adult female voice)
    - Mechanical turk version uses written sentences
- Exposure set: 
    - 72 total sentences paired with corresponding picture
    - each noun is paired with a specific plural marker (see [Language](#language))
    - 1/3 of presentations were singular and 2/3 plural for each noun
    - plurals appeared in groups of 2, 4, or 6
    - Zipfian distribution
- Production test set:
    - All novel nouns presented twice: `bleggin`, `daffin`, `norg`, `sep`, `flugit`, `geed`
    - plurals appeared in groups of 3 or 5
- Rating test set:
    - All 9 familiar nouns presented 4 times in 2AFC
        - paired with four different incorrect markers

## Procedure
- Exposure: 
    - see a picture and hear the sentence that goes with the picture
    - repeat the sentence
    - break every 18 trials (for sticker)
- Production test:
    - modeled after wug test (Berko, 1958)
    - see a singular picture and hear corresponding sentence
    - participant asked to produce plural sentence for same noun
    - importantly, adults are given a 1.5 second time limit
        - hear a beep and box on screen turns red
        - told they will get a 50 cent bonus for every trial on which they can produced within the time limit
- Rating test:
    - 2AFC test in which there is a child in a purple shirt and a child in a green shirt on the screen
    - participant must decide which child said the sentences correctly in silly speak


# Results and analysis

```{r settingup, echo=FALSE, message=FALSE}

### Setting up
# We begin by loading the required packages, setting up some figure parameters, and specifying file paths.

# Install packages you don't have -----------------------------------------------
# install.packages("dplyr", repos= "http://lib.stat.cmu.edu/R/CRAN/")
# install.packages("data.table", repos= "http://lib.stat.cmu.edu/R/CRAN/")
# install.packages("tidyr", repos= "http://lib.stat.cmu.edu/R/CRAN/")
# install.packages("ggplot2", repos= "http://lib.stat.cmu.edu/R/CRAN/")
# Tells you what versions of things you are runing in your R session -------------
# sessionInfo() 

library(data.table)
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)

# set the experiment id (change this for every study) and path
EXPNUM <- '0167'
EXPID <- '0167-empiricalyang-9noun-hfrule-adults-fastproduction'

# if we are analyzing a current experiment
EXPPATH <- '~/Dropbox/kschuler-current/'
# if we are analyzing an archived experiment
#EXPPATH <- '~/Dropbox/kschuler-all/'

# setup paths for data and figures
SUBJ_TRACK <- paste(EXPPATH, 'subject-tracking/',  EXPID, '-track.csv', sep = "")
DATA_PATH <- paste(EXPPATH, 'processed-data/', EXPID, '-processed/', sep = "")

# standard error function
SEM <- function (x) {
    return(sd(x)/sqrt(length(x)))
}

# theme to add to all plots
THEME_KDS <- theme_classic(base_size = 15) +
    theme(axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
          axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.ticks.x = element_blank())
theme_set(THEME_KDS)

# Import subject tracking sheet
subjects <- fread(SUBJ_TRACK) %>%
  tbl_df

# Import and combine subject production data and merge with subject tracking
prod.data <- list.files(paste(DATA_PATH, '/production/gaby-coded', sep=""), full.names = TRUE) %>%
    lapply(fread, drop = 15:19) %>%
    bind_rows %>%
    tbl_df %>%
    left_join(subjects, by  = c("subject")) %>%
    select(experiment, exp.version, language, speed, condition.y, subject, gender, age, type, noun, plural, categoryDet, corrNoun, KDS.exclude)

# Import and combine subject rating data and merge with subject tracking
rate.data <- list.files(paste(DATA_PATH, '/rating', sep=""), full.names = TRUE) %>%
    lapply(fread) %>%
    bind_rows %>%
    tbl_df %>%
    left_join(subjects, by =c("subject")) 

# save the production and rating data to processed data
write.csv(prod.data, paste(DATA_PATH, "/0167-production-data-summary-all.csv", sep=""))
write.csv(rate.data, paste(DATA_PATH, "/0167-rating-data-summary-all.csv", sep=""))
```

## Preregistration

#### Planned number of subjects
We will run 10 subjects in each condition (5R4E and 3R6E) to compare with our original yang experiment (0161)
 
  - Update 2016-12-12: Research assistant accidentally ran 5 additional subjects in 5R4E, so we have expanded to 15 in each condition to balance this out.
  
#### Planned data cleaning
We will exclude participants who:

- are flagged for exclusion via KDS.exclude because:
    - did not meet inclusion criteria (age, language experience, normal to corrected-to-normal hearing/vision)
    - did not complete the study 
    - equipment malfuncation during experiment
 

#### Planned analyses
We plan to run the same analysis we always run on our empirical yang work.  

1. Simple t-tests against hypothesized values (100% for rule formation, 14.79% for chance, and token frequency of regular)
2. Comparision of the two conditions may be required (do they apply the regular form more in 5R4E than 3R6E?)
3. Comparision of this experiment to participants in the original yang experiment (0161) may be required - do pariticpants apply the regular form significantly less in 3R6E and signficantly more in 5R4E?

### Included in analysis
The following describes the participants that were included in analysis for both experiment conditions.


```{r, echo = FALSE, fig.width=6, fig.height=4}
# 
subjects %>% filter(KDS.exclude == 0) %>%
  mutate(isfemale = ifelse(gender == "female", 1, 0)) %>%
  group_by(condition)%>%
  summarise(n.subjs = n(), n.female = sum(isfemale), min.age = min(age), max.age = max(age), mean.age = mean(age), sd.age = sd(age)) %>%
  kable

```


### Excluded from analysis
The folowing participants were excluded from analyses.  Reasons for exclusion are given in the notes.

```{r, echo = FALSE, message = FALSE, fig.width=6, fig.height=4}

subjects %>% filter(KDS.exclude == 1) %>%
  arrange(condition) %>% 
  select(condition, subject, gender, age, notes) %>%
  kable
```

## Production Data

We ask the following questions in our analysis (for both children and adults):

- Does the Tolerance Principle predict when learners will form a productive rule?
    - Do learners use the regular form on 100% of test trials (strongly generalize/form a rule)?
    - Or do learners use the regular form no more than what we expect by chance (strongly resist rule formation)?
    - Or do learners match the input frequency of the regular form (probability match)?

### Group data



```{r, echo = FALSE, message = FALSE, fig.width=5, fig.height=4}
# calculate the criteria above for production data
prod.criteria <- group_by(prod.data, condition.y, subject, type) %>%
  summarise(totaltrials = n(), n.correct.nouns = sum(corrNoun))

# # merge with prod.criteria and use n.correct.nouns to calculate percent correct for each subject
prod.data <- left_join(prod.data, prod.criteria, by = c("condition.y", "subject", "type")) %>%
  filter(corrNoun == 1) %>%
  group_by(condition.y, type, subject, categoryDet, n.correct.nouns)%>%
  summarise(n.det = n()) %>% as.data.frame %>%
  complete(nesting(condition.y, type, subject, n.correct.nouns), categoryDet, fill = list(n.det = 0)) %>%
  mutate(pcnt.usage = 100*(n.det/n.correct.nouns))


# get the mean and SEM pcntusage for the group 
prod.data.group <- group_by(prod.data, condition.y, type, categoryDet) %>%
  summarise(n.subjs = n(), mean.pcntusage = mean(pcnt.usage), sd.usage = sd(pcnt.usage), se.usage = SEM(pcnt.usage))

# get a table of the results and make it pretty
prod.data.table <- rename(prod.data.group, Condition = condition.y, 
                          plural.marker = categoryDet, Mean = mean.pcntusage, SD = sd.usage, SEM = se.usage)
kable(prod.data.table, digits = 2, caption = "Usage of plural marker in production test by age group")
# # 
# # 
# 
# # do some ttests 
# # get a table of the results and make it pretty
# prod.data.table <- filter(prod.data.group, prod.det.category == "R") %>% 
#   select(age.group, condition.y, n.subjs, mean.pcntusage, se.usage) %>%
#   rename(Condition = condition.y, N = n.subjs, Mean = mean.pcntusage, SEM = se.usage)
# kable(prod.data.table, digits = 2, caption = "Mean percentage usage for each condition")
#   
# # get the mean percent usage for each condition
# cond.5R4E <- filter(prod.data, condition.y == "5R4E", prod.det.category == "R")
# cond.3R6E <- filter(prod.data, condition.y == "3R6E", prod.det.category == "R")
# 
# # t.test againts hypothesized value of 100%
# test1 = t.test(cond.5R4E$pcnt.usage, mu = 100, alternative = "less")
# # result1 = data.frame("t.statistic" = test1$statistic, "df" = test1$parameter, "p.value" = test1$p.value,
# #                      row.names = "Condition 5R4E v. 100%")
# # kable(result1, caption = "Is children's usage of the regular form in 5R4E different from 100% (prediction of Tolerance Principle?)")
# 
# test2 = t.test(cond.3R6E$pcnt.usage, mu = 14.29)
# # result2 = data.frame("t.statistic" = test2$statistic, "df" = test2$parameter, "p.value" = test2$p.value,
# #                      row.names = "Condition 3R6E v. 14.29%")
# # kable(result2, caption = "Is children's usage of the regular form in 3R6E different from 14.29% (prediction of Tolerance Principle?)")
# 
# # t.test against frequency in each condition
# test3 = t.test(cond.5R4E$pcnt.usage, mu = 75.51, alternative = "greater")
# test4 = t.test(cond.3R6E$pcnt.usage, mu = 59.18, alternative = "less")
# 
# test5 = t.test(cond.5R4E$pcnt.usage,cond.3R6E$pcnt.usage)
# 
# 
# result.table = data.frame("alternative" = c("less", "not equal", "greater", "less", "not equal"),
#                       "t.statistic"  = c(test1$statistic, test2$statistic, test3$statistic, test4$statistic, test5$statistic),
#                        "df" = c(test1$parameter, test2$parameter, test3$parameter, test4$parameter, test5$parameter),
#                         "p.value"  = c(test1$p.value, test2$p.value, test3$p.value, test4$p.value, test5$p.value),
#                         "sig" = c("n.s.", "n.s", "*", "**", "***"),
#                         # "lower CL" = test3$conf.int[1],
#                         # "upper CL" = test3$conf.int[2],
#                         # "OJ mean" = test3$estimate[1],
#                         # "VC mean" = test3$estimate[2],
#                          row.names = c("Condition 5R4E v. Tolerance Principle prediction (100%)", "Condition 3R6E v. Tolerance Principle prediction (14.29%)", "Condition 5R4E v. Token Fq. (75.51%)", "Condition 3R6E v. Token Fq. (59.18%)", "Condition 5R4E v. Condition 3R6E"))
# 
# kable(result.table, caption = "Results of T-Tests")
# 


```

### Plot of group data
The dashed lines indicate the frequency of the regular form in the learners exposure.


```{r, echo = FALSE, message = FALSE, fig.width=5, fig.height=4}
# # plot the data with lines for the prediction of the tolerance principle
probmatch_prediction = data.frame(condition.y = c("5R4E", "3R6E"), fq = c(75, 60))
prod.data$condition.y = factor(prod.data$condition.y, levels = c("5R4E", "3R6E"))
prod.data.group <- left_join(prod.data.group, probmatch_prediction, on = "condition.y")
prod.data.group$condition.y = factor(prod.data.group$condition.y, levels = c("5R4E", "3R6E"))
prod.data.group$categoryDet = factor(prod.data.group$categoryDet, levels = c("R", "e", "null"))

# 
# 
# # plot the data 

ggplot(prod.data.group, aes(categoryDet, mean.pcntusage, fill = categoryDet)) +
  facet_grid(~condition.y) +
    geom_bar(stat = "identity", position = position_dodge(), color = "black") +
    geom_errorbar(aes(ymin = mean.pcntusage - se.usage, ymax = mean.pcntusage + se.usage),
                  position = position_dodge(width = 0.9), width = 0.25) +
    scale_fill_manual(values=c("#5dc2dd", "#696969", "#A9A9A9", "#D3D3D3"))+
    coord_cartesian(ylim = c(0, 101)) +
    geom_hline(aes(yintercept = fq), linetype = "dashed", color = "black") +
    xlab("") +
    ylab("Usage of plural marker") +
    theme(legend.position = "none")

```





```{r, echo = FALSE, fig.width=6, fig.height=4}
# 
# # plot the data with lines for the token frequency
# summary_plot = data.frame(condition.y = c("5R4E", "3R6E", "5R4E", "3R6E","5R4E", "3R6E", "5R4E", "3R6E"), 
#                           mean = c(91.67, 16.86, 65.00, 52.05, 100, 14.29, 75.51, 59.18),
#                           se.usage = c(8.33, 12.20, 10.82, 10.49, NA, NA, NA, NA),
#                           type = c("Child data", "Child data", "Adult data", "Adult data", "Tolerance principle", "Tolerance principle", "Token frequency", "Token frequency"))
# 
# summary_plot$type <- factor(summary_plot$type, 
#     levels = c("Tolerance principle", "Child data",  "Adult data", "Token frequency"),
#     labels = c("Tolerance \nprinciple", "Child data", "Adult data", "Token \nfrequency"))
# summary_plot$condition.y <- factor(summary_plot$condition.y, levels = c("5R4E", "3R6E"))
# 
# 
# ggplot(summary_plot, aes(condition.y, mean, fill = type)) +
#     facet_grid(. ~ type) +
#     geom_bar(stat = "identity", position = position_dodge(), color = "black", width = 0.75) +
#     geom_errorbar(aes(ymin = mean - se.usage, ymax = mean + se.usage),
#                   position = position_dodge(width = 0.9), width = 0.25) +
#     scale_fill_manual(values=c("red","#5dc2dd", "#5dc2dd", "#D3D3D3"))+
#     coord_cartesian(ylim = c(0, 101)) +
#     xlab("") +
#     ylab("Usage of regular form") +
#     theme(legend.position = "none")
# 

```


```{r, echo = FALSE, message = FALSE, fig.width=4, fig.height=3}
# 
# prod.data$age.group <- factor(prod.data$age.group,
#                               levels = c("child", "adult"), labels = c("Child data", "Adult data"))
prod.data <- left_join(prod.data, probmatch_prediction, on = "condition.y")
prod.data$condition.y = factor(prod.data$condition.y, levels = c("5R4E", "3R6E"))
prod.data$categoryDet = factor(prod.data$categoryDet, levels = c("R", "e", "null"))
# 
# # plot pcnt.usage for ka by individual subject
ggplot(filter(prod.data, categoryDet == 'R'), aes(type, pcnt.usage, fill = type)) +
  facet_grid(~condition.y)+
  geom_dotplot(binaxis = 'y', stackdir = "center", binwidth = 5, fill = "#5dc2dd") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.25) +
  geom_hline(aes(yintercept = fq), linetype = "dashed", color = "black") +
  xlab("")+
  ylab("Usage of regular form") + theme(legend.position = "none")


```

## Rating Data

- get and plot 

```{r, echo = FALSE, fig.height= 3, fig.width=4}
rate.data.exclude <- group_by(rate.data, subject) %>%
  summarise(total.trials = n(), total.distinct = n_distinct(rating)) %>%
  left_join(rate.data, by = c("subject")) %>% print
# 
# # 
# rate.data <- rate.data.exclude %>% filter(total.distinct > 1)
# # 
# # rate.data$condition.y <- factor(rate.data$condition.y, levels = c("5R4E", "3R6E"))
# # rate.data$categoryDet <- factor(rate.data$categoryDet, levels = c("R", "e"), labels = c("regular \nnouns", "exceptional \nnouns"))
# # rate.data$type <- factor(rate.data$type, levels = c("correct", "incorrect"))
# # 
# 
# rate.data
# 
# rate.data.1 <- select(rate.data, age.group, subject, noun, type, rating) %>%
#   group_by(subject) %>%
#   mutate(z.rating = (rating - mean(rating))/sd(rating)) %>%
#   group_by(age.group, subject, noun, type) %>%
#   summarise(mean.rating = mean(rating), se.rating = SEM(rating), mean.zscore = mean(z.rating), se.zscore = SEM(z.rating)) %>%
#   group_by(age.group, type) %>%
#   summarise(mean.z = mean(mean.zscore), se.z = SEM(mean.zscore)) %>%
#     print
# 
# # 
# # # # 
# ggplot(rate.data.1, aes(factor(type), mean.z, fill = type)) +
#   facet_grid(~age.group) +
#   geom_bar(stat = "identity", position = position_dodge(), color = "black", width = 0.75)+
#   geom_errorbar(aes(ymin = mean.z - se.z, ymax = mean.z + se.z),
#                   position = position_dodge(width = 0.75), width = 0.25) +
#   # scale_fill_manual(values=c("#D3D3D3", "red"), name = "")+
# 
#   xlab("") +
#   ylab("Rating (z-score)") +
#   theme(legend.position = "none")
# 
# # 
# rate.data.2 <- select(rate.data, condition.y, subject, noun.rank, corr.det.cat, type, rating) %>%
#   group_by(condition.y, subject) %>%
#   mutate(z.rating = (rating - mean(rating))/sd(rating)) %>%
#   group_by(condition.y, subject, noun.rank, type, corr.det.cat) %>%
#   summarise(mean.rating = mean(rating), se.rating = SEM(rating), mean.zscore = mean(z.rating), se.zscore = SEM(z.rating)) %>%
#   group_by(condition.y, corr.det.cat,noun.rank, type) %>%
#   summarise(mean.z = mean(mean.zscore), se.z = SEM(mean.zscore))
# 
# rate.data.2$corr.det.cat <- factor(rate.data.2$corr.det.cat, levels = c("regular \nnouns", "exceptional \nnouns"), labels = c("R", "e"))
# rate.data.2 <- mutate(rate.data.2, noun.label = paste(noun.rank, "\n", corr.det.cat, sep = ""))
# 
# ggplot(rate.data.2, aes(factor(noun.label), mean.z, fill = type)) +
#   facet_grid(~condition.y) +
#   geom_bar(stat = "identity", position = position_dodge(), color = "black", width = 0.75)+
#   geom_errorbar(aes(ymin = mean.z - se.z, ymax = mean.z + se.z),
#                   position = position_dodge(width = 0.75), width = 0.25) +
#   scale_fill_manual(values=c("#D3D3D3", "red"), name = "")+
#   # scale_fill_discrete(name = "New Legend Title")
#   xlab("") +
#   ylab("Rating (z-score)") 



```
